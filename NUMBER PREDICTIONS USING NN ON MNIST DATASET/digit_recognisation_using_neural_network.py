# -*- coding: utf-8 -*-
"""Digit recognisation using Neural Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19k7iyRtMmGoy7m7eCRNq_jKEGBZSgJ3v

### Introduction  

In this project, I will implement a neural network to classify handwritten digits using the MNIST dataset. The MNIST dataset comprises 28x28 grayscale images of handwritten digits ranging from 0 to 9. This project is a fundamental exercise in deep learning and image recognition, offering a solid understanding of how to handle image-based datasets. As a widely recognized benchmark problem, it serves as an ideal starting point for beginners in machine learning and neural networks.  

### Objective  

The primary goal of this project is to build a neural network capable of classifying handwritten digits into their respective classes. The system will be trained on labeled image data, enabling it to learn patterns associated with each digit. Ultimately, I aim to develop a predictive system that can correctly identify the digit in any new handwritten image provided as input.  

### Approach  

The project begins with data collection and preprocessing. Since the MNIST dataset is readily available in the Keras library, accessing it is straightforward. Preprocessing will include normalizing pixel values to a range of 0 to 1 and standardizing image dimensions. Labels for the images will be converted into one-hot encoded vectors.  

Next, I will construct a neural network comprising fully connected layers. The architecture will include:  
1. An **input layer** to accept the flattened image data.  
2. **Hidden layers** with activation functions to capture non-linear patterns.  
3. A final **output layer** with softmax activation for classifying digits.  

The model will be trained using the training dataset, optimized with the Adam optimizer, and evaluated on a separate test dataset. Key metrics, such as accuracy, will assess the model's performance.  

Finally, I will develop a predictive system. This system will take a new handwritten digit image as input and predict the corresponding digit. By completing this project, I aim to demonstrate the practical applications of neural networks in image recognition tasks and establish a robust foundation for tackling more complex deep learning challenges in the future.

step by Step Approch

1)importing the dataset

2)image processing

3)splitting the data into train_test spilt

4)building the neural network

5)training the neural network

6)giving new image to trained data

7)prediction is done on new image given to trained neural network.

**IMPORTING THE NECESSARY LIBRARIES AND DEPENDENCIES**
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras
from tensorflow.math import confusion_matrix

"""**IMPORTING THE DATASET WHICH IS IN KERAS**"""

from keras.datasets import mnist

"""so here in this dataset dta is already split into train test data so we just have to load it(for refrence you can visit keras mnist dataset on google)

Where

 Training data have 60,000 Images

& Test data has 10,000 Images

Image dimension = 28 x 28

Grayscale Image = 1 channel
"""

(X_train, Y_train), (X_test, Y_test) =  mnist.load_data()

type(X_train)

print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)

print(X_train[5])

print(X_train[10].shape)

#DISPLAYING THE IMAGE

plt.imshow(X_train[20])
plt.show()


print(Y_train[20])

print(Y_train.shape, Y_test.shape)

#PRINTING UNIQUE VALUES INi Y_train
print(np.unique(Y_train))

#PRINTING UNIQUE VALUES IN Y_test
print(np.unique(Y_test))

"""We can use these labels as such or we can also apply One Hot Encoding

All the images have the same dimensions in this dataset, If not, we have to resize all the images to a common dimension
"""

#SCALING THE VALUES
X_train = X_train/255
X_test = X_test/255

print(X_train[10])

"""**BUILDING NEURAL NETWORK**"""

model = keras.Sequential([
                          keras.layers.Flatten(input_shape=(28,28)),
                          keras.layers.Dense(50, activation='relu'),
                          keras.layers.Dense(50, activation='relu'),
                          keras.layers.Dense(50, activation='relu'),
                          keras.layers.Dense(10, activation='sigmoid')
])

"""**NOW COMPLILING THE NN**"""

model.compile(optimizer='adam',
              loss = 'sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""**NOW TRAINING THE NN**"""

model.fit(X_train, Y_train, epochs=20)

"""accuracy: 99.40

**NOR FOR ACCURACY ON TEST DATA**
"""

loss, accuracy = model.evaluate(X_test, Y_test)
print(accuracy)

"""Accuracy :97.00"""

print(X_test.shape)

#NOW FOR FIRST DATA POINT OF X_test
plt.imshow(X_test[0])
plt.show()

print(Y_test[0])

#NOW FOR ANY RANDOM NUMBER OF DATA POINT OF X_test
plt.imshow(X_test[277])
plt.show()

print(Y_test[277])

Y_pred = model.predict(X_test)

print(Y_pred.shape)

print(Y_pred[0])

#CONVERTING THE PREDICTION PROBABLITIES TO CLASS LABEL FOR FIRST DATA POINT.
label_for_first_test_image = np.argmax(Y_pred[0])
print(label_for_first_test_image)

#NOW FOR ALL DATA POINTS
Y_pred_labels = [np.argmax(i) for i in Y_pred]
print(Y_pred_labels)

"""WHERE

Y_test = True labels

Y_pred_labels = Predicted Labels

**NOW CREATIN CONFUSION MATRIX**
"""

conf_mat = confusion_matrix(Y_test, Y_pred_labels)

print(conf_mat)

plt.figure(figsize=(8,5))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Greens')
plt.ylabel('True Labels')
plt.xlabel('Predicted Labels')

"""**NOW BUILDING A PREDICTIVE SYSTEM**"""

input_image_path = '/content/MNIST_digit.png'

input_image = cv2.imread(input_image_path)

type(input_image)

print(input_image)

import cv2
import numpy as np
import requests
from google.colab.patches import cv2_imshow

# Load the image from the URL
url = 'https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png'
response = requests.get(url, stream=True).raw
input_image = np.asarray(bytearray(response.read()), dtype="uint8")
input_image = cv2.imdecode(input_image, cv2.IMREAD_GRAYSCALE)

# Check image dimensions
print(f"Image dimensions: {input_image.shape}")

# Crop a single digit (adjust coordinates based on the specific image layout)
# Example: Cropping the first digit (coordinates may vary)
single_digit = input_image[5:50, 5:50]  # Replace with the coordinates of the desired digit

# Display the single digit
cv2_imshow(single_digit)

input_image.shape

grayscale = input_image  # The image is already in grayscale

grayscale.shape

input_image_resize = cv2.resize(grayscale, (28, 28))

input_image_resize.shape

cv2_imshow(input_image_resize)

input_image_resize = input_image_resize/255

type(input_image_resize)

image_reshaped = np.reshape(input_image_resize, [1,28,28])

input_prediction = model.predict(image_reshaped)
print(input_prediction)

input_pred_label = np.argmax(input_prediction)

print(input_pred_label)

"""**Predictive System**"""

input_image_path = input('Path of the image to be predicted: ')

input_image = cv2.imread(input_image_path)

cv2_imshow(input_image)

grayscale = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)

input_image_resize = cv2.resize(grayscale, (28, 28))

input_image_resize = input_image_resize/255

image_reshaped = np.reshape(input_image_resize, [1,28,28])

input_prediction = model.predict(image_reshaped)

input_pred_label = np.argmax(input_prediction)

print('The Handwritten Digit is recognised as ', input_pred_label)